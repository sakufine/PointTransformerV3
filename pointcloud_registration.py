"""
ç‚¹äº‘é…å‡†ï¼ˆå¯¹é½ä¸¤ä¸ªç‚¹äº‘ï¼‰
ä½¿ç”¨ PTv3 ç‰¹å¾è¿›è¡Œç‰¹å¾åŒ¹é… + ICP ç²¾ç¡®é…å‡†
"""

import torch
import numpy as np
import open3d as o3d
from pathlib import Path
from inference import PTv3Inference
from scipy.spatial.distance import cdist
from scipy.spatial import cKDTree

class PointCloudRegistration:
    """ç‚¹äº‘é…å‡†ç±»"""
    
    def __init__(self, weights_path: str = None, grid_size: float = 0.02, device: str = 'cuda'):
        """
        åˆå§‹åŒ–é…å‡†å™¨
        
        Args:
            weights_path: PTv3 æƒé‡è·¯å¾„
            grid_size: ä½“ç´ å¤§å°
            device: è®¡ç®—è®¾å¤‡
        """
        self.inferencer = PTv3Inference(
            weights_path=weights_path,
            grid_size=grid_size,
            device=device,
            enable_flash=True,  # å¯ä»¥å¯ç”¨ Flash Attention
        )
    
    def extract_features(self, coords: np.ndarray, colors: np.ndarray = None) -> torch.Tensor:
        data_dict = self.inferencer.preprocess(coords, colors)
        with torch.no_grad():
            output = self.inferencer.model(data_dict)
        feat = output.feat.cpu()
        # æ–°å¢ï¼šL2 å½’ä¸€åŒ–
        feat = torch.nn.functional.normalize(feat, p=2, dim=1)
        return feat
    
    def feature_matching(
        self, 
        feat1: torch.Tensor, 
        feat2: torch.Tensor,
        ratio_threshold: float = 0.8
    ) -> tuple:
        """
        ä½¿ç”¨ KDTree ä¼˜åŒ–ç‰¹å¾åŒ¹é…ï¼Œé¿å… 53GB çš„å†…å­˜æº¢å‡º
        """
        # è½¬æ¢ä¸º float32 èŠ‚çœå†…å­˜
        feat1_np = feat1.numpy().astype(np.float32)
        feat2_np = feat2.numpy().astype(np.float32)
        
        # æ„å»ºç›®æ ‡ç‚¹äº‘ç‰¹å¾çš„ KDTree
        tree = cKDTree(feat2_np)
        
        # æŸ¥è¯¢ feat1 ä¸­æ¯ä¸ªç‚¹åœ¨ feat2 ä¸­çš„ 2 ä¸ªæœ€è¿‘é‚» (ç”¨äº Ratio Test)
        # k=2, workers=-1 è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒå¹¶è¡ŒåŠ é€Ÿ
        distances, indices = tree.query(feat1_np, k=2, workers=-1)
        
        matches = []
        match_distances = []
        
        # æ‰§è¡Œ Lowe's Ratio Test
        for i in range(len(feat1_np)):
            d0, d1 = distances[i]
            if d0 < ratio_threshold * d1:
                matches.append([i, indices[i, 0]])
                match_distances.append(d0)
                
        if len(matches) == 0:
            return np.array([]), np.array([])
        
        matches = np.array(matches)
        match_distances = np.array(match_distances)
        
        # æŒ‰ç…§è·ç¦»æ’åº
        sort_idx = np.argsort(match_distances)
        return matches[sort_idx], match_distances[sort_idx]
    
    def ransac_alignment(
        self,
        coords1: np.ndarray,
        coords2: np.ndarray,
        matches: np.ndarray,
        num_iterations: int = 5000,
        threshold: float = 0.5,
        num_samples: int = 4
    ) -> tuple:
        """
        RANSAC ç²—é…å‡†
        
        Args:
            coords1: ç‚¹äº‘1åæ ‡ (N1, 3)
            coords2: ç‚¹äº‘2åæ ‡ (N2, 3)
            matches: åŒ¹é…ç‚¹å¯¹ (M, 2)
            num_iterations: RANSAC è¿­ä»£æ¬¡æ•°
            threshold: å†…ç‚¹é˜ˆå€¼
            num_samples: æ¯æ¬¡é‡‡æ ·ç‚¹æ•°
            
        Returns:
            transform: 4x4 å˜æ¢çŸ©é˜µ
            inliers: å†…ç‚¹ç´¢å¼•
        """
        if len(matches) < num_samples:
            return np.eye(4), np.array([])
        
        best_transform = np.eye(4)
        best_inliers = np.array([])
        max_inliers = 0
        
        points1 = coords1[matches[:, 0]]
        points2 = coords2[matches[:, 1]]
        
        for _ in range(num_iterations):
            # éšæœºé‡‡æ ·
            sample_idx = np.random.choice(len(matches), num_samples, replace=False)
            sample_p1 = points1[sample_idx]
            sample_p2 = points2[sample_idx]
            
            # è®¡ç®—å˜æ¢çŸ©é˜µï¼ˆæœ€å°äºŒä¹˜ï¼‰
            try:
                # è®¡ç®—ä¸­å¿ƒ
                center1 = sample_p1.mean(axis=0)
                center2 = sample_p2.mean(axis=0)
                
                # å»ä¸­å¿ƒåŒ–
                p1_centered = sample_p1 - center1
                p2_centered = sample_p2 - center2
                
                # SVD åˆ†è§£æ±‚æ—‹è½¬
                H = p1_centered.T @ p2_centered
                U, S, Vt = np.linalg.svd(H)
                R = Vt.T @ U.T
                
                # ç¡®ä¿æ˜¯æ—‹è½¬çŸ©é˜µï¼ˆè¡Œåˆ—å¼ä¸º1ï¼‰
                if np.linalg.det(R) < 0:
                    Vt[-1, :] *= -1
                    R = Vt.T @ U.T
                
                # è®¡ç®—å¹³ç§»
                t = center2 - R @ center1
                
                # æ„å»ºå˜æ¢çŸ©é˜µ
                transform = np.eye(4)
                transform[:3, :3] = R
                transform[:3, 3] = t
                
                # åº”ç”¨å˜æ¢å¹¶è®¡ç®—å†…ç‚¹
                transformed_p1 = (R @ points1.T).T + t
                distances = np.linalg.norm(transformed_p1 - points2, axis=1)
                inliers = np.where(distances < threshold)[0]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_transform = transform
                    best_inliers = matches[inliers]
                    
            except:
                continue
        
        return best_transform, best_inliers
    
    def icp_refinement(
        self,
        coords1: np.ndarray,
        coords2: np.ndarray,
        init_transform: np.ndarray = None,
        max_iterations: int = 50,
        threshold: float = 0.02
    ) -> tuple:
        """
        ICP ç²¾é…å‡†
        
        Args:
            coords1: ç‚¹äº‘1åæ ‡ (N1, 3)
            coords2: ç‚¹äº‘2åæ ‡ (N2, 3)
            init_transform: åˆå§‹å˜æ¢çŸ©é˜µ (4x4)
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            threshold: è·ç¦»é˜ˆå€¼
            
        Returns:
            transform: æœ€ç»ˆå˜æ¢çŸ©é˜µ (4x4)
            fitness: é…å‡†è´¨é‡åˆ†æ•° [0, 1]
        """
        # è½¬æ¢ä¸º Open3D æ ¼å¼
        pcd1 = o3d.geometry.PointCloud()
        pcd1.points = o3d.utility.Vector3dVector(coords1)
        
        pcd2 = o3d.geometry.PointCloud()
        pcd2.points = o3d.utility.Vector3dVector(coords2)
        
        # åˆå§‹å˜æ¢
        if init_transform is not None:
            pcd1.transform(init_transform)
        
        # ICP é…å‡†
        result = o3d.pipelines.registration.registration_icp(
            pcd1, pcd2, threshold,
            np.eye(4),
            o3d.pipelines.registration.TransformationEstimationPointToPoint(),
            o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=max_iterations)
        )
        
        # ç»„åˆå˜æ¢
        if init_transform is not None:
            final_transform = result.transformation @ init_transform
        else:
            final_transform = result.transformation
        
        return final_transform, result.fitness
    
    def register(
        self,
        coords1: np.ndarray,
        coords2: np.ndarray,
        colors1: np.ndarray = None,
        colors2: np.ndarray = None,
        use_feature_matching: bool = True
    ) -> tuple:
        """
        å®Œæ•´é…å‡†æµç¨‹
        
        Args:
            coords1: æºç‚¹äº‘åæ ‡ (N1, 3)
            coords2: ç›®æ ‡ç‚¹äº‘åæ ‡ (N2, 3)
            colors1: æºç‚¹äº‘é¢œè‰²ï¼Œå¯é€‰
            colors2: ç›®æ ‡ç‚¹äº‘é¢œè‰²ï¼Œå¯é€‰
            use_feature_matching: æ˜¯å¦ä½¿ç”¨ç‰¹å¾åŒ¹é…
            
        Returns:
            transform: å˜æ¢çŸ©é˜µ (4x4)ï¼Œå°† coords1 å˜æ¢åˆ° coords2 çš„åæ ‡ç³»
            aligned_coords1: å¯¹é½åçš„æºç‚¹äº‘åæ ‡
            fitness: é…å‡†è´¨é‡åˆ†æ•°
        """
        print("ğŸ”„ å¼€å§‹ç‚¹äº‘é…å‡†...")
        
        if use_feature_matching:
            # æ–¹æ³•1ï¼šç‰¹å¾åŒ¹é… + RANSAC + ICP
            print("  1ï¸âƒ£ æå–ç‰¹å¾...")
            feat1 = self.extract_features(coords1, colors1)
            feat2 = self.extract_features(coords2, colors2)
            print(f"     - ç‚¹äº‘1ç‰¹å¾: {feat1.shape}")
            print(f"     - ç‚¹äº‘2ç‰¹å¾: {feat2.shape}")
            
            print("  2ï¸âƒ£ ç‰¹å¾åŒ¹é…...")
            matches, match_distances = self.feature_matching(feat1, feat2)
            print(f"     - æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…ç‚¹å¯¹")
            
            if len(matches) > 3:
                print("  3ï¸âƒ£ RANSAC ç²—é…å‡†...")
                init_transform, inliers = self.ransac_alignment(
                    coords1, coords2, matches
                )
                print(f"     - å†…ç‚¹æ•°é‡: {len(inliers)}")
            else:
                print("  âš ï¸ åŒ¹é…ç‚¹å¯¹å¤ªå°‘ï¼Œä½¿ç”¨å•ä½çŸ©é˜µä½œä¸ºåˆå§‹å˜æ¢")
                init_transform = np.eye(4)
        else:
            # æ–¹æ³•2ï¼šç›´æ¥ ICPï¼ˆéœ€è¦åˆå§‹ä½ç½®æ¥è¿‘ï¼‰
            init_transform = np.eye(4)
        
        print("  4ï¸âƒ£ ICP ç²¾é…å‡†...")
        final_transform, fitness = self.icp_refinement(
            coords1, coords2, init_transform
        )
        print(f"âœ… é…å‡†å®Œæˆ! è´¨é‡åˆ†æ•°: {fitness:.3f}")
        
        # åº”ç”¨å˜æ¢
        R = final_transform[:3, :3]
        t = final_transform[:3, 3]
        aligned_coords1 = (R @ coords1.T).T + t
        
        return final_transform, aligned_coords1, fitness
    
    def visualize_registration(
        self,
        coords1: np.ndarray,
        coords2: np.ndarray,
        aligned_coords1: np.ndarray,
        colors1: np.ndarray = None,
        colors2: np.ndarray = None
    ):
        """
        å¯è§†åŒ–é…å‡†ç»“æœ
        
        Args:
            coords1: åŸå§‹æºç‚¹äº‘
            coords2: ç›®æ ‡ç‚¹äº‘
            aligned_coords1: å¯¹é½åçš„æºç‚¹äº‘
            colors1: æºç‚¹äº‘é¢œè‰²
            colors2: ç›®æ ‡ç‚¹äº‘é¢œè‰²
        """
        # åˆ›å»ºç‚¹äº‘
        pcd1_orig = o3d.geometry.PointCloud()
        pcd1_orig.points = o3d.utility.Vector3dVector(coords1)
        if colors1 is not None:
            pcd1_orig.colors = o3d.utility.Vector3dVector(colors1)
        else:
            pcd1_orig.paint_uniform_color([1, 0, 0])  # çº¢è‰²
        
        pcd1_aligned = o3d.geometry.PointCloud()
        pcd1_aligned.points = o3d.utility.Vector3dVector(aligned_coords1)
        if colors1 is not None:
            pcd1_aligned.colors = o3d.utility.Vector3dVector(colors1)
        else:
            pcd1_aligned.paint_uniform_color([0, 1, 0])  # ç»¿è‰²
        
        pcd2 = o3d.geometry.PointCloud()
        pcd2.points = o3d.utility.Vector3dVector(coords2)
        if colors2 is not None:
            pcd2.colors = o3d.utility.Vector3dVector(colors2)
        else:
            pcd2.paint_uniform_color([0, 0, 1])  # è“è‰²
        
        # å¯è§†åŒ–
        o3d.visualization.draw_geometries([pcd1_aligned, pcd2])


def main():
    """ç¤ºä¾‹ï¼šé…å‡†ä¸¤ä¸ªç‚¹äº‘"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç‚¹äº‘é…å‡†')
    parser.add_argument('--source', type=str, default="pointcloud/mouse.pcd", help='æºç‚¹äº‘è·¯å¾„')
    parser.add_argument('--target', type=str, default="pointcloud/mouse_right.pcd", help='ç›®æ ‡ç‚¹äº‘è·¯å¾„')
    parser.add_argument('--weights', type=str, default="models/sonata_small.pth", help='PTv3 æƒé‡è·¯å¾„')
    parser.add_argument('--output', type=str, default="pointcloud/mouse_registered.pcd", help='è¾“å‡ºå¯¹é½åçš„ç‚¹äº‘è·¯å¾„')
    parser.add_argument('--visualize', action='store_true', help='å¯è§†åŒ–ç»“æœ')
    
    args = parser.parse_args()
    
    # è¯»å–ç‚¹äº‘
    print("ğŸ“„ è¯»å–ç‚¹äº‘...")
    pcd1 = o3d.io.read_point_cloud(args.source)
    pcd2 = o3d.io.read_point_cloud(args.target)
    
    coords1 = np.asarray(pcd1.points)
    coords2 = np.asarray(pcd2.points)
    colors1 = np.asarray(pcd1.colors) if pcd1.has_colors() else None
    colors2 = np.asarray(pcd2.colors) if pcd2.has_colors() else None
    
    print(f"   - æºç‚¹äº‘: {len(coords1)} ä¸ªç‚¹")
    print(f"   - ç›®æ ‡ç‚¹äº‘: {len(coords2)} ä¸ªç‚¹")
    
    # åˆ›å»ºé…å‡†å™¨
    registrar = PointCloudRegistration(weights_path=args.weights)
    
    # é…å‡†
    transform, aligned_coords1, fitness = registrar.register(
        coords1, coords2, colors1, colors2
    )
    
    # ä¿å­˜ç»“æœ
    if args.output:
        aligned_pcd = o3d.geometry.PointCloud()
        aligned_pcd.points = o3d.utility.Vector3dVector(aligned_coords1)
        if colors1 is not None:
            aligned_pcd.colors = o3d.utility.Vector3dVector(colors1)
        o3d.io.write_point_cloud(args.output, aligned_pcd)
        print(f"ğŸ’¾ å¯¹é½åçš„ç‚¹äº‘å·²ä¿å­˜: {args.output}")
    
    # å¯è§†åŒ–
    if args.visualize:
        registrar.visualize_registration(
            coords1, coords2, aligned_coords1, colors1, colors2
        )
    
    return transform, aligned_coords1, fitness


if __name__ == '__main__':
    main()

